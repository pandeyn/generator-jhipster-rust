//! Kafka consumer service for <%= baseName %>
//!
//! This module provides a Kafka consumer for consuming messages from Kafka topics
//! using the rdkafka library with async/await support.

use rdkafka::config::ClientConfig;
use rdkafka::consumer::{Consumer, StreamConsumer};
use rdkafka::message::Message;
use rdkafka::error::KafkaError;
use thiserror::Error;
use tokio::sync::broadcast;
use futures::StreamExt;

use crate::config::KafkaConfig;

/// Errors that can occur during Kafka consumer operations
#[derive(Error, Debug)]
pub enum KafkaConsumerError {
    #[error("Failed to create Kafka consumer: {0}")]
    CreationError(String),
    #[error("Failed to subscribe to topics: {0}")]
    SubscriptionError(String),
    #[error("Failed to consume message: {0}")]
    ConsumeError(String),
    #[error("Kafka consumer is not enabled")]
    NotEnabled,
    #[error("Message payload is not valid UTF-8")]
    InvalidPayload,
}

impl From<KafkaError> for KafkaConsumerError {
    fn from(err: KafkaError) -> Self {
        KafkaConsumerError::ConsumeError(err.to_string())
    }
}

/// A Kafka message received from a topic
#[derive(Debug, Clone)]
pub struct KafkaMessage {
    /// The topic the message was received from
    pub topic: String,
    /// The partition the message was received from
    pub partition: i32,
    /// The offset of the message
    pub offset: i64,
    /// The key of the message (if present)
    pub key: Option<String>,
    /// The payload of the message
    pub payload: String,
    /// The timestamp of the message (milliseconds since epoch)
    pub timestamp: Option<i64>,
}

/// Kafka consumer service for consuming messages
pub struct KafkaConsumer {
    consumer: StreamConsumer,
    config: KafkaConfig,
    /// Broadcast sender for distributing messages to multiple receivers
    message_sender: broadcast::Sender<KafkaMessage>,
}

impl KafkaConsumer {
    /// Create a new Kafka consumer with the given configuration
    pub fn new(config: KafkaConfig) -> Result<Self, KafkaConsumerError> {
        if !config.enabled {
            return Err(KafkaConsumerError::NotEnabled);
        }

        let mut client_config = ClientConfig::new();
        client_config
            .set("bootstrap.servers", &config.bootstrap_servers)
            .set("group.id", &config.group_id)
            .set("session.timeout.ms", config.session_timeout_ms.to_string())
            .set("enable.auto.commit", config.enable_auto_commit.to_string())
            .set(
                "auto.commit.interval.ms",
                config.auto_commit_interval_ms.to_string(),
            )
            .set("auto.offset.reset", &config.auto_offset_reset)
            .set("security.protocol", &config.security_protocol);

        // Add SASL configuration if provided
        if let Some(ref mechanism) = config.sasl_mechanism {
            client_config.set("sasl.mechanism", mechanism);
        }
        if let Some(ref username) = config.sasl_username {
            client_config.set("sasl.username", username);
        }
        if let Some(ref password) = config.sasl_password {
            client_config.set("sasl.password", password);
        }

        let consumer: StreamConsumer = client_config
            .create()
            .map_err(|e| KafkaConsumerError::CreationError(e.to_string()))?;

        // Create a broadcast channel for distributing messages
        let (message_sender, _) = broadcast::channel(1000);

        Ok(Self {
            consumer,
            config,
            message_sender,
        })
    }

    /// Subscribe to the default topic
    pub fn subscribe_default(&self) -> Result<(), KafkaConsumerError> {
        self.subscribe(&[&self.config.default_topic])
    }

    /// Subscribe to a list of topics
    pub fn subscribe(&self, topics: &[&str]) -> Result<(), KafkaConsumerError> {
        self.consumer
            .subscribe(topics)
            .map_err(|e| KafkaConsumerError::SubscriptionError(e.to_string()))?;

        tracing::info!(topics = ?topics, "Subscribed to Kafka topics");
        Ok(())
    }

    /// Get a receiver for messages
    /// Multiple receivers can be created to distribute messages to multiple handlers
    pub fn get_receiver(&self) -> broadcast::Receiver<KafkaMessage> {
        self.message_sender.subscribe()
    }

    /// Start consuming messages in a background task
    /// Messages are broadcast to all receivers created via `get_receiver()`
    pub async fn start_consuming(&self) {
        tracing::info!(
            group_id = %self.config.group_id,
            "Starting Kafka consumer"
        );

        let mut stream = self.consumer.stream();

        while let Some(result) = stream.next().await {
            match result {
                Ok(borrowed_message) => {
                    let topic = borrowed_message.topic().to_string();
                    let partition = borrowed_message.partition();
                    let offset = borrowed_message.offset();

                    let key = borrowed_message
                        .key()
                        .and_then(|k| std::str::from_utf8(k).ok())
                        .map(|s| s.to_string());

                    let payload = match borrowed_message.payload() {
                        Some(p) => match std::str::from_utf8(p) {
                            Ok(s) => s.to_string(),
                            Err(_) => {
                                tracing::warn!(
                                    topic = %topic,
                                    partition = partition,
                                    offset = offset,
                                    "Skipping message with invalid UTF-8 payload"
                                );
                                continue;
                            }
                        },
                        None => {
                            tracing::debug!(
                                topic = %topic,
                                partition = partition,
                                offset = offset,
                                "Skipping message with empty payload"
                            );
                            continue;
                        }
                    };

                    let timestamp = borrowed_message
                        .timestamp()
                        .to_millis();

                    let message = KafkaMessage {
                        topic: topic.clone(),
                        partition,
                        offset,
                        key,
                        payload,
                        timestamp,
                    };

                    tracing::debug!(
                        topic = %topic,
                        partition = partition,
                        offset = offset,
                        "Received message from Kafka"
                    );

                    // Broadcast the message to all receivers
                    // Ignore errors (no receivers connected)
                    let _ = self.message_sender.send(message);
                }
                Err(e) => {
                    tracing::error!(error = %e, "Error consuming message from Kafka");
                }
            }
        }
    }

    /// Get the consumer group ID
    pub fn group_id(&self) -> &str {
        &self.config.group_id
    }

    /// Get the default topic name
    pub fn default_topic(&self) -> &str {
        &self.config.default_topic
    }

    /// Check if the consumer is enabled
    pub fn is_enabled(&self) -> bool {
        self.config.enabled
    }
}
